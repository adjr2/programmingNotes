{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"parks.csv\",index_col='Park Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.loc is label based. prints out row matching the label.\n",
    "#to use this, index_col argument in pd.read_csv should be used\n",
    "data.loc['ACAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.iloc is integer position based\n",
    "#it doesn't matter whether labels are there or not. it works just fine\n",
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[['Park Name','State']] = data[['State','Park Name']]\n",
    "#This code will switch the values in the columns\n",
    "\n",
    "#however, .loc and .iloc will not modify it\n",
    "data.loc[:,['Park Name','State']] = data[['State','Park Name']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case we want to modify using loc then\n",
    "#data.loc[:,['Park Name','State']] = data[['State','Park Name']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['State'].head(2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing using .loc\n",
    "\n",
    "data[:'ARCH']\n",
    "data.loc[:'ARCH']\n",
    "#both give the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[:'ARCH']=0\n",
    "data1.loc[:'ARCH']=1\n",
    "#this will assign values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing via label slices\n",
    "data.loc[:'ARCH',['Park Name','State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for getting values with a boolean array.\n",
    "data.loc['ARCH']=='UT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for getting a value explicitly\n",
    "#this is equivalen to 'data.at['ARCH','State']\n",
    "data.loc['ARCH','State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting based on index\n",
    "data.sort_index().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is a good practice to change the header names as they names with space in them can create some trouble\n",
    "data.columns=[col.replace(' ','_').lower() for col in data.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in .iloc we need to know the exact location of the column\n",
    "#to get the location of the column\n",
    "data.columns.get_loc('Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complicated expressions, including lambdas\n",
    "data[data['Park Name'].str.split().apply(lambda x: len(x)==4)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isit method: returns a dataframe of booleans that is the same shape as the original dataframe with True wherever the element is in the sequence of values.\n",
    "#data.isin(['WA','OR','CA']).head()\n",
    "data[data.State.isin(['WA','OR','CA'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Manipulation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=pd.read_csv(\"basic_salary2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as summary() in R\n",
    "salary.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of the data\n",
    "salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary[['Last_Name', 'First_Name']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting using a criteria; like subset() in R\n",
    "salary3=salary[(salary.Location == 'DELHI') & (salary.ba >20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check the nan in the data\n",
    "pd.isnull(salary).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show row which have nan. any() returns whether any element is True over requested axis. Its's format is pandas.dataframe.any\n",
    "salary[pd.isnull(salary).any(axis=1)].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary6=salary[(salary.Grade!=\"GR!\") & (salary.Location!='MUMBAI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting of data frame using pandas\n",
    "salary.sort_values(by='ba', ascending=False).head(2)\n",
    "\n",
    "#sorting by multiple columns\n",
    "salary.sort_values(by=['Grade','ba']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To delete a variable\n",
    "%reset_selective sorted_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different ways of joining two or more dataframes.\n",
    "\n",
    "#Concatenation\n",
    "join=pd.concat([salary, salary3], ignore_index=True)\n",
    "#like rbind() in R\n",
    "join3=pd.concat([salary, salary3], axis=1)\n",
    "\n",
    "#Append\n",
    "join1=salary.append(salary3, ignore_index=True)\n",
    "\n",
    "#Merge\n",
    "sal_data=pd.read_csv(\"sal_data.csv\")\n",
    "bonus_data=pd.read_csv(\"bonus_data.csv\")\n",
    "join2=pd.merge(sal_data, bonus_data,how='outer',on='Employee_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate \n",
    "A=salary.groupby('Location').agg({'ba':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To rename the column\n",
    "salary.rename(columns={'ba':'Basic Allowance'}, inplace=True)\n",
    "\n",
    "#The following command can be used to rename all or some of the columns.\n",
    "#salary.columns=[''] when index is not mention, it can be used to rename all the columns\n",
    "#salary.columns[3]=[''] it will rename column 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding new column\n",
    "salary['Bonus']=salary['Basic Allowance']*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like the ifelse() in R, to change value stored in the column\n",
    "salary['Location']=np.where(salary['Location']=='MUMBAI',1,2)\n",
    "\n",
    "#np.where for multiple conditions\n",
    "salary['Category']=np.where(salary['Basic Allowance']<14000,\"Low\",(np.where(salary['Basic Allowance']<19000,\"Medium\",\"High\")))\n",
    "\n",
    "#cut function like the function in R.\n",
    "pd.cut(salary['Basic Allowance'], [0,14000,19000, np.inf], labels=['Low','Medium','High']).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove first 5 rows\n",
    "salary.drop(salary.index[0:5],inplace=True) \n",
    "\n",
    "#to remove columns\n",
    "salary.drop(['Category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Table\n",
    "pd.crosstab(index=salary.Grade,columns=salary.Function)\n",
    "\n",
    "#Three-way Frequency Table\n",
    "pd.crosstab(index=[salary.Grade, salary.Location],columns=salary.Function)\n",
    "\n",
    "#Proportion table\n",
    "pd.crosstab(index=salary.Grade, columns=salary.Function, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting variables to the date format\n",
    "\n",
    "#in both the cases variable is stored as object type\n",
    "\n",
    "#to run these refer to youtube_analysis repository\n",
    "#if the date is in some other format:\n",
    "final['trending_date']=pd.to_datetime(final['trending_date'],format='%y.%d.%m')\n",
    "\n",
    "#if variable is in proper format but stored as object:\n",
    "final['publish_time']=pd.to_datetime(final['publish_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to extract only date\n",
    "final['publish_time'].dt.date\n",
    "\n",
    "#to extract only time\n",
    "final['publish_time'].dt.time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
